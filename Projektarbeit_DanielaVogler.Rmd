---
title: "Detektion von Sepsiserkrankungen in Intensivpatienten"
subtitle: "Projektarbeit im Zertifikatsprogramm \"Medical Data Science\""
author: "Daniela Vogler"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output: 
  pdf_document:
    toc: true
    toc_depth: 2
    number_sections: true
    keep_tex: yes
header-includes:
  - \renewcommand{\tablename}{Tabelle}
  - \renewcommand{\contentsname}{Inhalt}
  - \renewcommand{\figurename}{Abb.}
  - \usepackage{booktabs}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  - \usepackage{wrapfig}
  - \usepackage{float}
  - \usepackage{colortbl}
  - \usepackage{pdflscape}
  - \usepackage{tabu}
  - \usepackage{threeparttable}
  - \usepackage{threeparttablex}
  - \usepackage[normalem]{ulem}
  - \usepackage[utf8]{inputenc}
  - \usepackage{makecell}
  - \usepackage{xcolor}
  - \floatplacement{figure}{H}
bibliography: bibliography.bib
fontsize: 12pt
editor_options: 
  markdown: 
  wrap: 80
---

```{r setup, include = FALSE, cache = FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	fig.pos = "H",
	warning = FALSE,
	cache = TRUE,
	cache.comments = FALSE,
	include = FALSE
)
```

```{r requirements, include = FALSE, cache = FALSE}
library(tidyverse)
library(here)
library(kableExtra)
library(grid)
library(gridExtra)
library(reshape)
library(rpart)
library(rpart.plot)
library(caret)
library(MLmetrics)
library(randomForest)
library(ranger)
library(gbm)
library(naniar)
```

```{r loading data, cache = TRUE}
data_complete <- read.csv(here("data/Dataset.csv"))

var_info <- read.csv2(
  here("data/Datensatzbeschreibung.csv")
  )
```

```{r subsampling}
# Subsample ziehen, um die Datenmenge besser handhaben zu können
set.seed(12345)

n <- round(0.1*length(unique(data_complete$Patient_ID)))

data_sample_index <- data_complete %>% 
  distinct(Patient_ID) %>% 
  sample_n(n)

data_sample <- data_complete %>% 
  filter(Patient_ID %in% data_sample_index$Patient_ID)
```

\newpage

# Einleitung

Eine Sepsis ist eine sehr ernste gesundheitliche Komplikation, insbesondere auf 
Intensivstationen. Die Sterblichkeitsrate liegt bei schweren Verläufen je nach 
genauer Abgrenzung der Diagnosen bei um die 50% und höher. Eine frühzeitige
Erkennung und damit einhergehend eine rechtzeitige Therapie gelten als wichtigste
Mittel zur Verbesserung der Überlebensrate. 

In dem geplanten Projekt sollen daher Möglichkeiten untersucht werden, eine Sepsis
anhand diverser Blutwerte und Vitalparameter, die üblicherweise im Rahmen von
Intensivbehandlungen erhoben werden, mittels prädiktiver Modelle zu erkennen, bevor sie klinisch diagnostiziert wird.

\newpage

# Datenexploration und -bereinigung

```{r data structure}
summary(data_sample)
str(data_sample)

# Outcome pro Patient abspeichern
outcome <- data_sample %>% 
  group_by(Patient_ID) %>% 
  mutate(Sepsis = max(SepsisLabel)) %>% 
  ungroup() %>% 
  select(Patient_ID, Sepsis) %>% 
  unique()

table(outcome$Sepsis)
```
Bei Betrachtung der Zusammenfassung des Datensatzes fallen zwei Fehler auf:

1. *FiO2* (inspiratorische Sauerstofffraktion) drückt einen Anteil aus und muss 
daher zwischen 0 und 1 liegen. Die Werte außerhalb dieses Bereichs werden daher 
entfernt.

2. *HospAdmTime*, die Zeit zwischen Hospitalisierung und Verlegung auf die 
Intensivstation, ist je nach Berechnung entweder positiv oder negativ, kann aber
nicht sowohl positive als auch negative Werte annehmen, da niemand auf die 
Intensivstation verlegt werden kann, bevor er überhaupt im Krankenhaus ist. Es 
ist daher naheliegend, dass unterschiedliche Berechnungen 
(Aufnahmezeitpunkt_gesamt - Aufnahmezeitpunkt_Intensiv und 
Aufnahmezeitpunkt_Intensiv - Aufnahmezeitpunkt_gesamt) vorgenomen worden. Ich 
vereinheitliche hier auf positive Vorzeichen, da diese für die Interpretation 
geeigneter sind ("Zeit, die zwischen Aufnahme im Krankenhaus und Aufnahme auf der 
ITS vergangen ist").

```{r data cleaning}
data_sample %>%
  filter(FiO2 < 0 | FiO2 > 1)

data_sample %>%
  filter(HospAdmTime > 0) %>% 
  distinct(Patient_ID, HospAdmTime)

data_sample <- data_sample %>% 
  mutate(FiO2 = case_when(FiO2 >= 0 & FiO2 <= 1 ~ FiO2),
         HospAdmTime = case_when(HospAdmTime < 0 ~ -1*HospAdmTime,
                                 TRUE ~ HospAdmTime)
         )
```

```{r data preparation}
data_sample <- data_sample %>% 
  mutate(Gender = factor(Gender, levels = c(0, 1), labels = c("W", "M")),
         Unit1 = factor(Unit1, levels = c(0, 1), labels = c("nein", "ja")),
         Unit2 = factor(Unit2, levels = c(0, 1), labels = c("nein", "ja")),
         SepsisLabel = factor(SepsisLabel, levels = c(1,0), 
                              labels = c("positiv", "negativ")
                              )
  )

outcome <- outcome %>% 
  mutate(Sepsis = factor(Sepsis, levels = c(1, 0),
                         labels = c("positiv", "negativ")
                        )                                
         )  # "positiv" muss 1. Klasse sein, damit caret später die Gütemaße 
            # geeignet zuordnet            

# Zur weiteren Verwendung wird jedem Datensatz der Outcome über den gesamten Zeitraum hinzugefügt
data_sample <- merge(data_sample, outcome, by = "Patient_ID")
```

Wir analysieren die Daten nun auf Korrelationen zwischen den numerischen Variablen 
und betrachten dazu eine Heatmap der Korrelationskoeffizienten nach Pearson:

```{r data correlation, fig.cap="Korrelationskoeffizienten nach Pearson", fig.height=8, fig.width=12, message=FALSE, warning=FALSE, include = TRUE}
data_sample %>% 
  select_if(is.numeric) %>%  
  select(-Patient_ID, -X) %>% 
  GGally::ggcorr(method = c("pairwise.complete.obs", "pearson"),
         label = TRUE, label_size = 2, label_alpha = TRUE) 
```

Baum-basierte Methoden funktionieren auch bei starker Multikollinearität gut, da 
sukzessive einzelne Variablen für die Splits herangezogen werden. Liefert eine 
Variable keinen oder kaum Informationsgewinn, weil sie stark mit einer vorher 
bereits zum Split genutzten Variable korreliert, wird sie nicht verwendet. Daher
müssen wir uns hier keine allzu großen Sorgen um die Korrelationen machen.
Allerdings sollten starke Kollinearitäten später bei der Interpretation der
Entscheidungskriterien berücksichtigt werden. Es ist möglich, dass nicht die
eigentlich relevante Variable für einen Split herangezogen wird, sondern eine, 
die stark mit ihr korreliert ist.

Bei Variablen mit vollständigen linearen Zusammenhang 
(Korrelationskoeffizient +/- 1) ist eine Variablenselektion dennoch angeraten:

Hour dient nur zur Information und soll nicht als Einflussvariable verwendet
werden. Daher kann sie hier vernachlässigt werden.

```{r Bilirubin}
data_sample %>% 
  filter(is.na(Bilirubin_total) & !is.na(Bilirubin_direct)) %>% 
  summarize(n())

data_sample %>% 
  filter(is.na(Bilirubin_direct) & !is.na(Bilirubin_total)) %>% 
  summarize(n())
```

Da es nur sehr wenige Beobachtungen gibt, in denen das Gesamt-Bilirubin fehlt, 
aber direkts Bilirubin gemessen wurde, andersherum jedoch einige Beobachtungen 
existieren, die eine Messung des Gesamt-Bilirubins enthalten, aber keine des 
direkten Bilirubins, wird die Variable *Bilirubin_direct* aus dem Datensatz
entfernt.

```{r Hct Hgb}
data_sample %>% 
  filter(is.na(Hct) & !is.na(Hgb)) %>% 
  summarize(n())

data_sample %>% 
  filter(is.na(Hgb) & !is.na(Hct)) %>% 
  summarize(n())
```

Hämoglobin- und Hämatokrit-Wert entsprechen einander ungefähr, weil die
Erythrozyten den Großteil des Gesamtvolumens der Blutzellen ausmachen
[@Haematokrit]. Ich entscheide daher auch hier nach Vollständigkeit der
Beobachtungen und entferne die Variable *Hgb* aus dem Datensatz.

```{r variable selection}
data_sample <- data_sample %>% 
  select(-Bilirubin_direct, -Hgb)
```

Bei Betrachtung der Boxplots der möglichen numerischen Einflussfaktoren fällt 
keine Variable durch besonders deutliche Unterschiede zwischen Patienten mit und 
ohne Sepsis auf.

Da schwerwiegende Erkrankungen durchaus extreme medizinische Werte hervorbringen 
können, ist es schwierig festzulegen, wann Ausreißer Messfehler sind und daher 
aus der Betrachtung herausgenommen werden sollten. Zudem sind Baum-basierte 
Methoden robust gegenüber Ausreißern. Deshalb werden hier keine weiteren 
Beobachtungen entfernt.

```{r boxplots, include = TRUE, warning = FALSE, fig.height=8, fig.width=10, fig.cap="Boxplots der numerischen Einflussfaktoren"}
# Numerische Einflussfaktoren in Bezug zum temporären Sepsisstatus
melt_sample <- data_sample %>% 
  select(-Gender, -Unit1, -Unit2, ) %>% 
  melt(., id.vars = c("Patient_ID", "X", "Hour", "SepsisLabel", "Sepsis"))

p <- ggplot(melt_sample, aes(factor(variable), value)) + 
  geom_boxplot(aes(fill = SepsisLabel)) + 
  labs(x = "", y = "") +
  facet_wrap(~variable, scale = "free") +
  theme(strip.background = element_blank(), strip.text = element_blank())

p

rm(melt_sample, p)
```

Da Temperatur und Blutwerte häufig nur einmal täglich bestimmt werden, wurden 
diese bei fehlenden Werten bis zu 24 Stunden fortgeschrieben (LOCF).

```{r LOCF imputation, warnings = FALSE}
data_sample_imputed <- data_sample %>% 
  pivot_longer(cols = Temp | BaseExcess:Platelets, 
               names_to = "var", 
               values_to = "value") %>% 
  group_by(Patient_ID, var) %>% 
  mutate(last_Hour = max(Hour[!is.na(value)]), 
         diff = Hour - last_Hour) %>% 
  fill(value) %>% 
  mutate(value = replace(value, which(diff > 24), NA)) %>% 
  select(-last_Hour, -diff) %>% 
  pivot_wider(names_from = var, values_from = value) %>% 
  relocate(Temp, .after = O2Sat) %>% 
  relocate(BaseExcess:Platelets, .after = EtCO2) %>% 
  as.data.frame()
```

\newpage

# Methoden und Ergebnisse

Nach den grundlegenden Vorbereitungen aus dem vorigen Kapitel ergeben sich zwei 
wesentliche Herausforderungen aus der Datenstruktur:

Zum einen fehlen in vielen Variablen sehr viele Werte. Es muss also ein Weg
gefunden werden, dennoch gute Ergebnisse zu erhalten.

Zum anderen müssen die longitudinalen Daten für die Anwendung Baum-basierter 
Verfahren zu je einer Beobachtung pro Patient zusammengefasst werden. Dazu werden 
drei Ansätze miteinander verglichen:

**1. Baseline-Datensatz:** Es werden alle Datensätze mit Hour = 1, d. h. die zweite
vorliegende Messung, verwendet. Die Wahl fällt deshalb nicht auf die erste Messung,
weil in dieser besonders viele Werte fehlen. Es ist zu beachten, dass der Zeitpunkt
der ersten Messung nicht notwendigerweise mit der Aufnahme auf die Intensivstation
zusammenfällt.
\newline Dieses Vorgehen entspricht einer einmaligen Beurteilung der Patienten zu 
Beginn der Intensivbehandlung bzw. zum erstmöglichen Zeitpunkt.

**2. Onset-Datensatz:** Für Sepsispatienten wird die erste mit einem positiven 
Outcome gelabelte Beobachtung verwendet. Für Nicht-Sepsispatienten wird eine 
Beobachtung zufällig ausgewählt, da nicht bekannt ist, wann ein solcher Patient 
der Entwicklung einer Sepsis am nächsten war.
\newline Dieser Ansatz simuliert eine regelmäßige Klassifikation liegender 
Intensivpatienten anhand ihrer jeweils aktuellen klinischen Parameter.

**3. Regressionsdatensatz:** Für jeden Patienten wird mittels linearer Regression 
die Entwicklung jeder Prädiktorvariable modelliert und der
patientenindividuelle Slope als Prädiktor verwendet. Dabei wird für 
Nicht-Sepsispatienten der gesamte Beobachtungszeitraum einbezogen und für
Sepsispatienten der Zeitraum bis zum ersten positiven Outcome.
\newline Dies entspricht einer regelmäßigen Klassifikation der Patienten anhand 
aller ihrer bis dahin vorliegenden Parameter.

Die drei entstandenen Datensätze werden anschließend jeweils in einen Trainings-
und Validierungsdatensatz mit 75% der Beobachtungen und einen Testdatensatz mit
den restlichen 25% der Beobachtungen aufgeteilt.

```{r creating baseline dataset}
# Es sollen die Messwerte zur Stunde 1 verwendet werden, aber für den Outcome
# ist der Gesamtzeitraum entscheidend
dataset1 <- data_sample_imputed %>%
  filter(Hour == 1) %>%
  select(-SepsisLabel)
```

```{r creating onset dataset}
# Es sollen die Beobachtungen zum Zeitpunkt des ersten positiven Labels verwendet
# werden, für Nicht-Sepsispatienten ein zufälliger Zeitpunkt
data_pos <- data_sample_imputed %>%
  filter(SepsisLabel == "positiv") %>%
  group_by(Patient_ID) %>%
  mutate(ersteSepsisflag = min(Hour)) %>%
  ungroup() %>%
  filter(Hour == ersteSepsisflag) %>%
  select(-ersteSepsisflag)

tmp_data_neg <- data_sample_imputed %>%
  filter(Sepsis == "negativ") %>%
  group_by(Patient_ID) %>%
  summarize(max_Hour = max(Hour),
            selected_Hour = sample(c(1:max_Hour),
                                    size = 1, replace = F)
            )

data_neg <- data_sample_imputed %>%
  filter(Sepsis == "negativ") %>%
  merge(., tmp_data_neg, by = "Patient_ID") %>%
  filter(Hour == selected_Hour) %>%
  select(-max_Hour, -selected_Hour)


dataset2 <- union_all(data_pos, data_neg) %>%
  select(-SepsisLabel) %>%
  as.data.frame()

rm(data_pos, data_neg, tmp_data_neg)
```

```{r creating regression dataset}
# Anstelle der Vital- und Laborwerte sollen die patientenindividuellen Slopes
# verwendet werden. Wenn ein Patient eine Sepsis entwickelt, wird nur der Zeitraum 
# bis zum ersten positiven Label betrachtet.

patient_model <- function(df) {
  if (sum(!is.na(df$yvalue)) < 2) NA
  else lm(yvalue ~ Hour, data = df)$coeff[2]
  }

data_pos <- data_sample_imputed %>%
  filter(SepsisLabel == "positiv") %>%
  group_by(Patient_ID) %>%
  mutate(ersteSepsisflag = min(Hour),
         ICULOS_end = min(ICULOS)) %>%
  distinct(Patient_ID, ersteSepsisflag, ICULOS_end)

data_sub <- data_sample_imputed %>%
  merge(., data_pos, by = "Patient_ID", all.x = TRUE) %>%
  filter(Sepsis == "negativ" |
           (ersteSepsisflag > 0 &  Hour <= ersteSepsisflag)
         # für ersteSepsisFlag = 0 lässt sich keine Entwicklung aufzeigen
         ) %>%
  group_by(Patient_ID) %>%
  mutate(ICULOS = case_when(!is.na(ICULOS_end) ~ ICULOS_end,
                            TRUE ~ max(ICULOS))) %>%
  ungroup() %>%
  pivot_longer(cols = HR:Platelets,
               names_to = "yvar",
               values_to = "yvalue") %>%
  mutate(yvar = paste("slope_", yvar, sep = "")) # eindeutige Namen erzeugen

by_patient <- data_sub %>%
  group_by(Patient_ID, yvar, ICULOS) %>% # damit ICULOS erhalten bleibt
  nest() %>%
  mutate(slope = map(data, patient_model)) %>%
  unnest(slope) %>%
  select(-data) %>%
  pivot_wider(names_from = yvar, values_from = slope)

dataset3 <- data_sample_imputed %>%
  distinct(Patient_ID, Age, Gender, Unit1, Unit2, HospAdmTime, Sepsis) %>%
  merge(by_patient, by = "Patient_ID", all = FALSE) %>%
  select(Patient_ID, Sepsis, everything())

rm(by_patient, data_sub, data_pos)
```

```{r train and test sets}
set.seed(12345)

# caret::createDataPartition balanciert die Outcome-Varaible aus
# der train_index für Datensatz 1 kann auch für Datensatz 2 genutzt werden (gleiche
# Patienten, gleicher Outcome)
train_index1 <- createDataPartition(dataset1$Sepsis, p = 0.75, list = FALSE)

# Datensatz 3 benötigt einen anderen train_index, da hier nicht alle Patienten 
# enthalten sind
train_index3 <- createDataPartition(dataset3$Sepsis, p = 0.75, list = FALSE)

train1 <- dataset1[train_index1,]
test1  <- dataset1[-train_index1,]
train2 <- dataset2[train_index1,]
test2  <- dataset2[-train_index1,]
train3 <- dataset3[train_index3,]
test3  <- dataset3[-train_index3,]
```

In den nächsten Abschnitten werden Entscheidungsbäume und Ensembles für jeweils
einen Datensatz angepasst. Das Tuning der Parameter und der Modellvergleich 
erfolgen mittels des R-Pakets *caret*.
Es wird eine 5-fache Kreuzvalidierung und aufgrund der sehr unausgewogenen Daten
(Eventrate `r prettyNum(
  round(
  length(unique((subset(data_sample, Sepsis == "positiv"))$Patient_ID)) /
  length(unique(data_sample$Patient_ID))   *100,
  digits = 1),
  decimal.mark = ",", big.mark = ".")` %) ein Upsampling vorgenommen.

Bei der Wahl der Evaluierungsmetrik ist zu berücksichtigen, dass sowohl
Sensitivität als auch Spezifität eine hohe Relevanz für die Fragestellung haben. 
Je höher die Sensitivität, desto mehr Patienten können frühzeitig behandelt werden,
je niedriger die Spezifität, desto mehr Patienten werden möglicherweise aufgrund
der Klassifizierung unnötigen Therapien unterzogen. Eine häufige Wahl ist in
solchen Situationen die *Area under the Curve (ROC)*. Für stark unausgewogene Daten
sind aber Metriken, die auf Precision und Recall beruhen, von Vorteil. Daher bieten
sich hier die *Area under the Precision Recall Curve (AUC)* und die F1-Metrik
(harmonisches Mittel aus Precision und Recall) an. 

Wir werden später beim Modellvergleich sehen, dass die AUC-Metrik im Vergleich zur
F1-Metrik falsch positive Klassifizierungen stärker bestraft und dafür eine
niedrige Detektionsrate in Kauf nimmt. Für diese Arbeit ist die Entscheidung für
die F1-Metrik gefallen. Sie berücksichtigt gleichermaßen den Anteil der richtig
positiven an den Events als auch der Anteil der richtig positiven an den insgesamt
positiv klassifizierten Beobachtungen, kann aber leicht so verallgemeinert werden,
dass entweder der Recall (= Sensitivität) oder die Präzision stärker gewichtet
werden. Eine flexible Anpassung beispielsweise im Rahmen einer klinischer Anwendung
ist also gegeben.

```{r caret models control}
set.seed(12345)

ctrl <- trainControl(method = "cv", number = 5,
                     classProbs = TRUE,
                     summaryFunction = prSummary,
                     sampling = "up")
```

```{r tune grid rf}
rf_grid <- expand.grid(
  .mtry = seq(2,35,3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)
```

```{r tune grid gbm}
gbm_grid <-  expand.grid(interaction.depth = seq(1, 9, 2),
                        n.trees = c(100, 500, 1000),
                        shrinkage = c(0.001, 0.01, 0.05, 0.1),
                        n.minobsinnode = seq(5, 20, 5))
```

## Der Baseline-Ansatz

Es wird ein Entscheidungsbaum mit dem CART-Algorithmus (R-Paket *rpart*) erstellt.
Da CART mit fehlenden Werten mittels Surrogate-Splits automatisch umgehen kann,
ist kein Preprocessing notwendig.

```{r cart model ds1}
set.seed(12345)

cart_ds1 <- train(x = train1[,4:41],
                  y = train1$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)
```

Das beste Modell ist: `r knitr::kable(cart_ds1$bestTune)`

```{r cart model results ds1, include = TRUE, fig.cap="Entscheidungsbaum Baseline-Datensatz"}
rpart.plot(cart_ds1$finalModel, type = 5)
```

Dass die Zeitspanne zwischen Krankenhausaufnahme und Verlegung auf die ITS eine
Rolle spielt, erscheint einleuchtend. Da hier jedoch gar keine weiteren Variablen
herangezogen werden, wird noch ein Baum ohne *HospAdmTime* angepasst. Dieser wird
mit Defaultparametern allerdings so tief, dass er nachträglich geprunt werden
muss, um visuelle Erkenntnisse aus der Baumstruktur zu ermöglichen. Der geeignete 
Complexity-Parameter wurde durch manuelles Ausprobieren bestimmt.

```{r cart model adjusted ds1}
set.seed(12345)

cart_adj_ds1 <- train(x = train1[,-c(1,2,3,40,42)],
                  y = train1$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

cart_adj_ds1 <- prune(cart_adj_ds1$finalModel, cp = 0.02)
```

```{r cart model adjusted results ds1, include = TRUE, fig.cap="Entscheidungsbaum Baseline-Datensatz angepasst"}
rpart.plot(cart_adj_ds1, type = 5)
```

```{r cart model test ds1}
pred_cart_ds1 <- predict(cart_ds1, test1)
confusionMatrix(data = pred_cart_ds1, reference = test1$Sepsis, 
                positive = "positiv")
```

Des Weiteren werden Random Forests trainiert. Da diese Methode nicht mit fehlenden
Werten funktioniert, wird zum einen die im R-Paket *randomForest* implementierte
Imputation nach Breiman angewandt [@Breiman]:

```{r rf model ds1}
set.seed(12345)

# Imputation nach Breiman:

ds1_imputed <- rfImpute(train1$Sepsis ~ ., train1) %>%
  dplyr::rename(Sepsis = `train1$Sepsis`) %>%
  relocate(Sepsis, .after = ICULOS)

rf_ds1 <- train(x = ds1_imputed[,4:41],
                y = train1$Sepsis,
                method = "ranger",
                tuneGrid = rf_grid,
                num.trees = 100,
                importance = "impurity",
                metric = "F",
                trControl = ctrl)
```

Das beste Modell ist: `r knitr::kable(rf_ds1$bestTune)`

```{r rf model test ds1}
# Testdaten werden nicht automatisch imputiert
pred_rf_ds1 <- predict(rf_ds1, rfImpute(Sepsis ~., test1)[-1])
confusionMatrix(data = pred_rf_ds1, reference = test1$Sepsis, 
                positive = "positiv")
```

Als weiterer Ansatz wird der Datensatz auf diejenigen Prädiktoren mit weniger als
30 % fehlenden Werten eingeschränkt und anschließend  nur die vollständigen
Beobachtungen einbezogen:

```{r non-missings ds1, include = TRUE, , fig.cap="Fehlende Werte im Baseline-Datensatz"}
vis_miss(dataset1)
```

```{r rf non-missing ds1}
set.seed(12345)

train1_2 <- train1[, which(colMeans(!is.na(train1)) > 0.7)] 

# Entsprechend muss mtry im TuneGrid angepasst werden:
n_var1 <- train1_2 %>% 
  select(-Patient_ID, -X, -Hour, -Sepsis) %>% 
  ncol()
  
rf_grid1 <- expand.grid(
  .mtry = seq(2, n_var1 - 1 ,3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)

rf_nm_ds1 <- train(Sepsis ~ . - Patient_ID - X - Hour - Sepsis,
                  data = train1_2,
                  method = "ranger",
                  na.action = na.omit,
                  tuneGrid = rf_grid1,
                  num.trees = 100,
                  importance = "impurity",
                  metric = "F",
                  trControl = ctrl)
``` 

Das beste Modell ist: `r knitr::kable(rf_nm_ds1$bestTune)`

```{r rf non-missing test ds1}
# Vorhersagen nur für vollständige Beobachtungen
test1_2 <- test1[, colnames(train1_2)] %>%
  filter(complete.cases(.))

pred_rf_nm_ds1 <- predict(rf_nm_ds1, test1_2)
confusionMatrix(data = pred_rf_nm_ds1, reference = test1_2$Sepsis, 
                positive = "positiv")
```

Während Random Forests Bäume durch Bagging kombinieren und damit insbesondere
die Korrelation zwischen den einzelnen Bäumen verringern, zielen auf Boosting
zurückgreifende Ensemble-Verfahren darauf, sukzessive die Vorhersagen für falsch
klassifizierte Beobachtungen zu verbessern. Hier wird nun zum Vergleich ein 
Stochastic Gradient Boosting mit dem R-Palet *gbm* durchgeführt:

```{r gbm model ds1}
set.seed(12345)

gbm_ds1 <- train(x = train1[,4:41],
                 y = train1$Sepsis,
                 method = "gbm",
                 distribution = "bernoulli", 
                 metric = "F",
                 tuneGrid = gbm_grid,
                 trControl = ctrl,
                 verbose = FALSE)
```

Das beste Modell ist: `r knitr::kable(gbm_ds1$bestTune)`

```{r gbm model test ds1}
pred_gbm_ds1 <- predict(gbm_ds1, test1)
confusionMatrix(data = pred_gbm_ds1, reference = test1$Sepsis, 
                positive = "positiv")
```

## Der Onset-Ansatz

Auch für den Onset-Datensatz werden zunächst Entscheidungsbäume mit dem
CART-Algorithmus angepasst und der Einfluss der Prädiktoren visualisiert:

```{r cart model ds2}
set.seed(12345)

cart_ds2 <- train(x = train2[,4:41],
                  y = train2$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

```

Das beste Modell ist: `r knitr::kable(cart_ds2$bestTune)`

```{r cart model results ds2, include = TRUE, fig.cap="Entscheidungsbaum Onset-Datensatz"}
rpart.plot(cart_ds2$finalModel, type = 5)
```

Ähnlich wie beim Baseline-Ansatz wird hier nur eine Prädiktorvariable verwendet - in diesem Fall die Länge des Intensivaufenthalts. Analog zum Vorgehen im vorigen
Abschnitt wird auch hier diese Variable ausgeschlossen:

```{r cart model adjusted ds2}
set.seed(12345)

cart_adj_ds2 <- train(x = train2[,4:40],
                  y = train2$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

```

```{r cart model adjusted results ds2, include = TRUE, fig.cap="Entscheidungsbaum Onset-Datensatz angepasst"}
rpart.plot(cart_ds2$finalModel, type = 5)
```

```{r cart model test ds2}
pred_cart_ds2 <- predict(cart_ds2, test2)
confusionMatrix(data = pred_cart_ds2, reference = test2$Sepsis, 
                positive = "positiv")
```

Es folgen die Random Forests - zunächst mit Imputation nach Breiman:

```{r rf model ds2}
set.seed(12345)

# Imputation nach Breiman:

ds2_imputed <- rfImpute(train2$Sepsis ~ ., train2) %>%
  dplyr::rename(Sepsis = `train2$Sepsis`) %>%
  relocate(Sepsis, .after = ICULOS)

rf_ds2 <- train(x = ds2_imputed[,4:41],
                y = train2$Sepsis,
                method = "ranger",
                tuneGrid = rf_grid,
                num.trees = 100,
                importance = "impurity",
                metric = "F",
                trControl = ctrl)
```

Das beste Modell ist: `r knitr::kable(rf_ds2$bestTune)`

```{r rf model test ds2}
# Testdaten werden nicht automatisch imputiert
pred_rf_ds2 <- predict(rf_ds2, rfImpute(Sepsis ~., test2)[-1])
confusionMatrix(data = pred_rf_ds2, reference = test2$Sepsis, 
                positive = "positiv")
```

Dann mit Einschränkung auf Prädiktoren mit weniger als 30 % fehlenden Werten
und vollständige Beobachtungen:

```{r non-missings ds2, include = TRUE, fig.cap="Fehlende Werte im Onset-Datensatz"}
vis_miss(dataset2)
```

```{r rf non-missing ds2}
set.seed(12345)

train2_2 <- train2[, which(colMeans(!is.na(train2)) > 0.7)] 

# Entsprechend muss mtry im TuneGrid angepasst werden:
n_var2 <- train2_2 %>% 
  select(-Patient_ID, -X, -Hour, -Sepsis) %>% 
  ncol()
  
rf_grid2 <- expand.grid(
  .mtry = seq(2, n_var2 - 1, 3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)

rf_nm_ds2 <- train(Sepsis ~ . - Patient_ID - X - Hour - Sepsis,
                  data = train2_2,
                  method = "ranger",
                  na.action = na.omit,
                  tuneGrid = rf_grid2,
                  num.trees = 100,
                  importance = "impurity",
                  metric = "F",
                  trControl = ctrl)
```

Das beste Modell ist: `r knitr::kable(rf_nm_ds2$bestTune)`

```{r rf non-missing test ds2}
# Vorhersagen nur für vollständige Beobachtungen
test2_2 <- test2[, colnames(train2_2)] %>%
  filter(complete.cases(.))

pred_rf_nm_ds2 <- predict(rf_nm_ds2, test2_2)
confusionMatrix(data = pred_rf_nm_ds2, reference = test2_2$Sepsis, 
                positive = "positiv")
```

Und schließlich wird ein Gradient Boosting durchgeführt:

```{r gbm model ds2}
set.seed(12345)

gbm_ds2 <- train(x = train2[,4:41],
                 y = train2$Sepsis,
                 method = "gbm",
                 distribution = "bernoulli",
                 metric = "F",
                 tuneGrid = gbm_grid,
                 trControl = ctrl,
                 verbose = FALSE)
```

Das beste Modell ist: `r knitr::kable(gbm_ds2$bestTune)`

```{r gbm model test ds2}
pred_gbm_ds2 <- predict(gbm_ds2, test2)
confusionMatrix(data = pred_gbm_ds2, reference = test2$Sepsis, 
                positive = "positiv")
```

## Der Regressionsansatz

Auch für den Regressionsdatensatz werden die gleichen Verfahren benutzt.

Mit dem CART-Algorithmus ergibt sich:

```{r cart model ds3}
set.seed(12345)

cart_ds3 <- train(x = train3[,3:40],
                  y = train3$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)
```

Das beste Modell ist: `r knitr::kable(cart_ds3$bestTune)`

```{r cart model results ds3, include = TRUE, fig.cap="Entscheidungsbaum Regressionsdatensatz"}
rpart.plot(cart_ds3$finalModel, type = 5)
```

Auch hier wird im finalen Modell nur die Dauer des Intensivaufenthalts als
Splitvariable verwendet und daher ein weiterer Baum ohne diesen Prädiktor
angepasst:

```{r cart model adjusted ds3}
set.seed(12345)

cart_adj_ds3 <- train(x = train3[,-c(1,2,8)],
                  y = train3$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)
```

```{r cart model adjusted results ds3, include = TRUE, fig.cap="Entscheidungsbaum Regressionsdatensatz angepasst"}
rpart.plot(cart_adj_ds3$finalModel, type = 5)
```

```{r cart model test ds3}
pred_cart_ds3 <- predict(cart_ds3, test3)
confusionMatrix(data = pred_cart_ds3, reference = test3$Sepsis, 
                positive = "positiv")
```

Random Forest mit Imputation nach Breiman:

```{r rf model ds3}
set.seed(12345)

# Imputation nach Breiman:

ds3_imputed <- rfImpute(train3$Sepsis ~ ., train3) %>%
  dplyr::rename(Sepsis = `train3$Sepsis`)

rf_ds3 <- train(x = ds3_imputed[,3:40],
                y = train3$Sepsis,
                method = "ranger",
                tuneGrid = rf_grid,
                num.trees = 100,
                importance = "impurity",
                metric = "F",
                trControl = ctrl)
```

Das beste Modell ist: `r knitr::kable(rf_ds3$bestTune)`

```{r rf model test ds3}
# Testdaten werden nicht automatisch imputiert
pred_rf_ds3 <- predict(rf_ds3, rfImpute(Sepsis ~., test3)[-1])
confusionMatrix(data = pred_rf_ds3, reference = test3$Sepsis,
                positive = "positiv")
```

Random Forest nach Einschränkung der Prädiktoren und auf vollständige
Beobachtungen:

```{r non-missings ds3, include = TRUE, fig.cap="fehlende Werte im Regressionsdatensatz"}
vis_miss(dataset3)
```

```{r rf non-missing ds3}
set.seed(12345)

train3_2 <- train3[, which(colMeans(!is.na(train3)) > 0.7)]

# Entsprechend muss mtry im TuneGrid angepasst werden:
n_var3 <- train3_2 %>% 
  select(-Patient_ID, -Sepsis) %>% 
  ncol()
  
rf_grid3 <- expand.grid(
  .mtry = seq(2, n_var3 - 1, 3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)

rf_nm_ds3 <- train(Sepsis ~ . - Patient_ID - Sepsis,
                  data = train3_2,
                  method = "ranger",
                  na.action = na.omit,
                  tuneGrid = rf_grid3,
                  num.trees = 100,
                  importance = "impurity",
                  metric = "F",
                  trControl = ctrl)
```

Das beste Modell ist: `r knitr::kable(rf_nm_ds3$bestTune)`

```{r rf non-missing test ds3}
# Vorhersagen nur für vollständige Beobachtungen
test3_2 <- test3[, colnames(train3_2)] %>%
  filter(complete.cases(.))

pred_rf_nm_ds3 <- predict(rf_nm_ds3, test3_2)
confusionMatrix(data = pred_rf_nm_ds3, reference = test3_2$Sepsis, 
                positive = "positiv")
```

Gradient Boosting:

```{r gbm model ds3}
set.seed(12345)

gbm_ds3 <- train(x = train3[,3:40],
                 y = train3$Sepsis,
                 method = "gbm",
                 distribution = "bernoulli",
                 metric = "F",
                 tuneGrid = gbm_grid,
                 trControl = ctrl,
                 verbose = FALSE)
```

Das beste Modell ist: `r knitr::kable(gbm_ds3$bestTune)`

```{r gbm model test ds3}
pred_gbm_ds3 <- predict(gbm_ds3, test3)
confusionMatrix(data = pred_gbm_ds3, reference = test3$Sepsis, 
                positive = "positiv")
```

\newpage

## Vergleich der Modelle

```{r resamples}
results <- resamples(list(ds1_cart = cart_ds1,
                          ds2_cart = cart_ds2,
                          ds3_cart = cart_ds3,
                          ds1_rf_rfImpute = rf_ds1, 
                          ds1_rf_nonmissing = rf_nm_ds1,
                          ds2_rf_rfImpute = rf_ds2, 
                          ds2_rf_nonmissing = rf_nm_ds2,
                          ds3_rf_rfImpute = rf_ds3, 
                          ds3_rf_nonmissing = rf_nm_ds3,
                          ds1_gbm = gbm_ds1, 
                          ds2_gbm = gbm_ds2, 
                          ds3_gbm = gbm_ds3))
```

```{r resamples F statistics, include = TRUE}
knitr::kable(summary(results)$statistics$F, 
             booktabs = T, 
             caption = "F-Metrik") %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position"),
                position = "center")
```

```{r resamples AUC statistics, include = TRUE}
knitr::kable(summary(results)$statistics$AUC, 
             booktabs = T, 
             caption = "AUC") %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position"),
                position = "center")
```

```{r resamples precision statistics, include = TRUE}
knitr::kable(summary(results)$statistics$Precision, 
             booktabs = T, 
             caption  = "Precision") %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position"),
                position = "center")
```

```{r resamples recall statistics, include = TRUE}
knitr::kable(summary(results)$statistics$Recall, 
             booktabs = T, 
             caption  = "Recall") %>%
  kable_styling(latex_options = c("striped", "scale_down", "hold_position"),
                position = "center")
```

\clearpage

```{r resamples plot, include = TRUE, fig.cap="Modellvergleich"}
dotplot(results)
```

```{r variable importance plot1, include = TRUE, fig.cap="Variablenwichtigkeit CART Baseline"}
plot(varImp(cart_ds1), top = 20, xlab = "")
```

```{r variable importance plot2, include = TRUE, fig.cap="Variablenwichtigkeit  CART Onset"}
plot(varImp(cart_ds2), top = 20, xlab = "")
```

```{r variable importance plot3, include = TRUE, fig.cap="Variablenwichtigkeit CART Regression"}
plot(varImp(cart_ds3), top = 20, xlab = "")
```

```{r variable importance plot4, include = TRUE, fig.cap="Variablenwichtigkeit  Random Forest Baseline"}
plot(varImp(rf_ds1), top = 20, xlab = "")
```

```{r variable importance plot5, include = TRUE, fig.cap="Variablenwichtigkeit Random Forest Onset"}
plot(varImp(rf_ds2), top = 20, xlab = "")
```

```{r variable importance plot6, include = TRUE, fig.cap="Variablenwichtigkeit  Random Forest Regression"}
plot(varImp(rf_ds3), top = 20, xlab = "")
```

```{r variable importance plot7, include = TRUE, fig.cap="Variablenwichtigkeit Random Forest (non-missing) Baseline"}
plot(varImp(rf_nm_ds1), top = 20, xlab = "")
```

```{r variable importance plot8, include = TRUE, fig.cap="Variablenwichtigkeit  Random Forest (non-missing) Onset"}
plot(varImp(rf_nm_ds2), top = 20, xlab = "")
```

```{r variable importance plot9, include = TRUE, fig.cap="Variablenwichtigkeit  Random Forest (non-missing) Regression"}
plot(varImp(rf_nm_ds3), top = 20, xlab = "")
```

```{r variable importance plot10, include = TRUE, fig.cap="Variablenwichtigkeit GBM Baseline"}
plot(varImp(gbm_ds1), top = 20, xlab = "")
```

```{r variable importance plot11, include = TRUE, fig.cap="Variablenwichtigkeit  GBM Onset"}
plot(varImp(gbm_ds2), top = 20, xlab = "")
```

```{r variable importance plot12, include = TRUE, fig.cap="Variablenwichtigkeit  GBM Regression"}
plot(varImp(gbm_ds3), top = 20, xlab = "")
```

\newpage

# Anhang

Es wurden folgende Pakete und Versionen von R genutzt:

```{r session info, include = TRUE, cache = FALSE}
sessioninfo::platform_info()$version
subset(data.frame(sessioninfo::package_info()), attached == TRUE, 
       c(loadedversion))
```

```{r vars description, include = TRUE}
knitr::kable(var_info, booktabs = T,
             caption = "Datensatzbeschreibung (Variablen)") %>%
  kable_styling(latex_options = c("striped", "scale_down"),
                position = "center")
```

\newpage

# Referenzen
