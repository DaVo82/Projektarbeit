---
title: "Detektion von Sepsiserkrankungen in Intensivpatienten"
subtitle: "Projektarbeit im Zertifikatsprogramm \"Medical Data Science\""
author: "Daniela Vogler"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
header-includes:
  \renewcommand{\tablename}{Tabelle}
  \renewcommand{\contentsname}{Inhalt}
output: 
  pdf_document:
  toc: true
  toc_depth: 2
  keep_tex: yes
  number_sections: true
bibliography: bibliography.bib
fontsize: 12pt
editor_options: 
  markdown: 
    wrap: 80
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  include = FALSE,
  cache = TRUE,
  cache.comments = FALSE,
  fig.pos = "H")
```

```{r requirements, include = FALSE, cache = FALSE}
library(tidyverse)
library(here)
library(kableExtra)
library(grid)
library(gridExtra)
library(reshape)
library(rpart)
library(rpart.plot)
library(caret)
library(MLmetrics)
library(randomForest)
library(ranger)
library(naniar)
```

```{r loading data, cache = TRUE}
data_complete <- read.csv(here("data/Dataset.csv"))

var_info <- read.csv2(
  here("data/Datensatzbeschreibung.csv")
  )
```

```{r Subsampling}
# Subsample ziehen, um die Datenmenge besser handhaben zu können
set.seed(12345)

n <- round(0.1*length(unique(data_complete$Patient_ID)))

data_sample_index <- data_complete %>% 
  distinct(Patient_ID) %>% 
  sample_n(n)

data_sample <- data_complete %>% 
  filter(Patient_ID %in% data_sample_index$Patient_ID)
```

# Einleitung

Eine Sepsis ist eine sehr ernste gesundheitliche Komplikation, insbesondere auf 
Intensivstationen. Die Sterblichkeitsrate liegt bei schweren Verläufen je nach 
genauer Abgrenzung der Diagnosen bei um die 50% und höher. Eine frühzeitige
Erkennung und damit einhergehend eine rechtzeitige Therapie gelten als wichtigste
Mittel zur Verbesserung der Überlebensrate. 

In dem geplanten Projekt sollen daher Möglichkeiten untersucht werden, eine Sepsis
anhand diverser Blutwerte und Vitalparameter, die üblicherweise im Rahmen von
Intensivbehandlungen erhoben werden, mittels prädiktiver Modelle zu erkennen, bevor
sie klinisch diagnostiziert wird.

# Datenexploration und -bereinigung

```{r data structure}
summary(data_sample)
str(data_sample)

# Outcome pro Patient abspeichern
outcome <- data_sample %>% 
  group_by(Patient_ID) %>% 
  mutate(Sepsis = max(SepsisLabel)) %>% 
  ungroup() %>% 
  select(Patient_ID, Sepsis) %>% 
  unique()

table(outcome$Sepsis)
```
Bei Betrachtung der Zusammenfassung des Datensatzes fallen zwei Fehler auf:

1. *FiO2* (inspiratorische Sauerstofffraktion) drückt einen Anteil aus und muss 
daher zwischen 0 und 1 liegen. Die Werte außerhalb dieses Bereichs werden daher 
entfernt.

2. *HospAdmTime*, die Zeit zwischen Hospitalisierung und Verlegung auf die 
Intensivstation, ist je nach Berechnung entweder positiv oder negativ, kann aber
nicht sowohl positive als auch negative Werte annehmen, da niemand auf die 
Intensivstation verlegt werden kann, bevor er überhaupt im Krankenhaus ist. Es 
ist daher naheliegend, dass unterschiedliche Berechnungen 
(Aufnahmezeitpunkt_gesamt - Aufnahmezeitpunkt_Intensiv und 
Aufnahmezeitpunkt_Intensiv - Aufnahmezeitpunkt_gesamt) vorgenomen worden. Ich 
vereinheitliche hier auf positive Vorzeichen, da diese für die Interpretation 
geeigneter sind ("Zeit, die zwischen Aufnahme im Krankenhaus und Aufnahme auf der 
ITS vergangen ist").

```{r data cleaning}
data_sample %>%
  filter(FiO2 < 0 | FiO2 > 1)

data_sample %>%
  filter(HospAdmTime > 0) %>% 
  distinct(Patient_ID, HospAdmTime)

data_sample <- data_sample %>% 
  mutate(FiO2 = case_when(FiO2 >= 0 & FiO2 <= 1 ~ FiO2),
         HospAdmTime = case_when(HospAdmTime < 0 ~ -1*HospAdmTime,
                                 TRUE ~ HospAdmTime)
         )
```

```{r data preparation}
data_sample <- data_sample %>% 
  mutate(Gender = factor(Gender, levels = c(0, 1), labels = c("W", "M")),
         Unit1 = factor(Unit1, levels = c(0, 1), labels = c("nein", "ja")),
         Unit2 = factor(Unit2, levels = c(0, 1), labels = c("nein", "ja")),
         SepsisLabel = factor(SepsisLabel, levels = c(1,0), 
                              labels = c("positiv", "negativ")
                              )
  )

outcome <- outcome %>% 
  mutate(Sepsis = factor(Sepsis, levels = c(1, 0),
                         labels = c("positiv", "negativ")
                        )                                
         )  # "positiv" muss 1. Klasse sein, damit caret später die Gütemaße 
            # geeignet zuordnet            

# Zur weiteren Verwendung wird jedem Datensatz der Outcome über den gesamten Zeitraum hinzugefügt
data_sample <- merge(data_sample, outcome, by = "Patient_ID")
```

Wir analysieren die Daten nun auf Korrelationen zwischen den numerischen Variablen 
und betrachten dazu eine Heatmap der Korrelationskoeffizienten nach Pearson:

```{r data correlation, fig.height=8, fig.width=12, message=TRUE, warning=FALSE, include = TRUE}
data_sample %>% 
  select_if(is.numeric) %>%  
  select(-Patient_ID, -X) %>% 
  GGally::ggcorr(method = c("pairwise.complete.obs", "pearson"),
         label = TRUE, label_size = 2, label_alpha = TRUE) + 
  labs(title = "Korrelationskoeffizienten nach Pearson")
```

Baum-basierte Methoden funktionieren auch bei starker Multikollinearität gut, da 
sukzessive einzelne Variablen für die Splits herangezogen werden. Liefert eine 
Variable keinen oder kaum Informationsgewinn, weil sie stark mit einer vorher 
bereits zum Split genutzten Variable korreliert, wird sie nicht verwendet. Daher
müssen wir uns hier keine allzu großen Sorgen um die Korrelationen machen.
Allerdings sollten starke Kollinearitäten später bei der Interpretation der
Entscheidungskriterien berücksichtigt werden. Es ist möglich, dass nicht die
eigentlich relevante Variable für einen Split herangezogen wird, sondern eine, 
die stark mit ihr korreliert ist.

Bei Variablen mit vollständigen linearen Zusammenhang 
(Korrelationskoeffizient +/- 1) ist eine Variablenselektion dennoch angeraten:

Hour dient nur zur Information und soll nicht als Einflussvariable verwendet
werden. Daher kann sie hier vernachlässigt werden.

```{r Bilirubin}
data_sample %>% 
  filter(is.na(Bilirubin_total) & !is.na(Bilirubin_direct)) %>% 
  summarize(n())

data_sample %>% 
  filter(is.na(Bilirubin_direct) & !is.na(Bilirubin_total)) %>% 
  summarize(n())
```

Da es nur sehr wenige Beobachtungen gibt, in denen das Gesamt-Bilirubin fehlt, 
aber direkts Bilirubin gemessen wurde, andersherum jedoch einige Beobachtungen 
existieren, die eine Messung des Gesamt-Bilirubins enthalten, aber keine des 
direkten Bilirubins, wird die Variable *Bilirubin_direct* aus dem Datensatz
entfernt.

```{r Hct Hgb}
data_sample %>% 
  filter(is.na(Hct) & !is.na(Hgb)) %>% 
  summarize(n())

data_sample %>% 
  filter(is.na(Hgb) & !is.na(Hct)) %>% 
  summarize(n())
```

Hämoglobin- und Hämatokrit-Wert entsprechen einander ungefähr, weil die
Erythrozyten den Großteil des Gesamtvolumens der Blutzellen ausmachen
[@Haematokrit]. Ich entscheide daher auch hier nach Vollständigkeit der
Beobachtungen und entferne die Variable *Hgb* aus dem Datensatz.

```{r variable selection}
data_sample <- data_sample %>% 
  select(-Bilirubin_direct, -Hgb)
```

Bei Betrachtung der Boxplots der möglichen numerischen Einflussfaktoren fällt 
keine Variable durch besonders deutliche Unterschiede zwischen Patienten mit und 
ohne Sepsis auf.

Da schwerwiegende Erkrankungen durchaus extreme medizinische Werte hervorbringen 
können, ist es schwierig festzulegen, wann Ausreißer Messfehler sind und daher 
aus der Betrachtung herausgenommen werden sollten. Zudem sind Baum-basierte 
Methoden robust gegenüber Ausreißern. Deshalb werden hier keine weiteren 
Beobachtungen entfernt.

```{r boxplots, include = TRUE, warning = FALSE, fig.height=8, fig.width=10, fig.cap="Boxplots der numerischen Einflussfaktoren"}
# Numerische Einflussfaktoren in Bezug zum temporären Sepsisstatus
melt_sample <- data_sample %>% 
  select(-Gender, -Unit1, -Unit2, ) %>% 
  melt(., id.vars = c("Patient_ID", "X", "Hour", "SepsisLabel", "Sepsis"))

p <- ggplot(melt_sample, aes(factor(variable), value)) + 
  geom_boxplot(aes(fill = SepsisLabel)) + 
   labs(x = "", y = "") +
  facet_wrap(~variable, scale = "free") +
  theme(strip.background = element_blank(), strip.text = element_blank())

p

rm(melt_sample, p)
```

Da Temperatur und Blutwerte häufig nur einmal täglich bestimmt werden, wurden 
diese bei fehlenden Werten bis zu 24 Stunden fortgeschrieben (LOCF).

```{r LOCF imputation, warnings = FALSE}
data_sample_imputed <- data_sample %>% 
  pivot_longer(cols = Temp | BaseExcess:Platelets, 
               names_to = "var", 
               values_to = "value") %>% 
  group_by(Patient_ID, var) %>% 
  mutate(last_Hour = max(Hour[!is.na(value)]), 
         diff = Hour - last_Hour) %>% 
  fill(value) %>% 
  mutate(value = replace(value, which(diff > 24), NA)) %>% 
  select(-last_Hour, -diff) %>% 
  pivot_wider(names_from = var, values_from = value) %>% 
  relocate(Temp, .after = O2Sat) %>% 
  relocate(BaseExcess:Platelets, .after = EtCO2) %>% 
  as.data.frame()
```

# Methoden und Ergebnisse

Nach den grundlegenden Vorbereitungen aus dem vorigen Kapitel ergeben sich zwei 
wesentliche Herausforderungen aus der Datenstruktur:

Zum einen fehlen in vielen Variablen sehr viele Werte. Es muss also ein Weg
gefunden werden, dennoch gute Ergebnisse zu erhalten.

Zum anderen müssen die longitudinalen Daten für die Anwendung Baum-basierter 
Verfahren zu je einer Beobachtung pro Patient zusammengefasst werden. Dazu werden 
drei Ansätze miteinander verglichen:

1. **Baseline-Datensatz:** Es werden alle Datensätze mit Hour = 1, d. h. die zweite
vorliegende Messung, verwendet. Die Wahl fällt deshalb nicht auf die erste Messung,
weil in dieser besonders viele Werte fehlen. Es ist zu beachten, dass der Zeitpunkt
der ersten Messung nicht notwendigerweise mit der Aufnahme auf die Intensivstation
zusammenfällt.
\newline Dieses Vorgehen entspricht einer einmaligen Beurteilung der Patienten zu 
Beginn der Intensivbehandlung bzw. zum erstmöglichen Zeitpunkt.

2. **Onset-Datensatz:** Für Sepsispatienten wird die erste mit einem positiven 
Outcome gelabelte Beobachtung verwendet. Für Nicht-Sepsispatienten wird eine 
Beobachtung zufällig ausgewählt, da nicht bekannt ist, wann ein solcher Patient 
der Entwicklung einer Sepsis am nächsten war.
\newline Dieser Ansatz simuliert eine regelmäßige Klassifikation liegender 
Intensivpatienten anhand ihrer jeweils aktuellen klinischen Parameter.

3. **Regressionsdatensatz:** Für jeden Patienten wird mittels linearer Regression 
die Entwicklung jeder einbezogenen Variable modelliert und der
patientenindividuelle Slope als Prädiktor verwendet. Dabei wird für 
Nicht-Sepsispatienten der gesamte Beobachtungszeitraum einbezogen und für
Sepsispatienten der Zeitraum bis zum ersten positiven Outcome.
\newline Dies entspricht einer regelmäßigen Klassifikation der Patienten anhand 
aller ihrer bis dahin vorliegenden Parameter.

Die drei entstandenen Datensätze werden anschließend jeweils in einen Trainings-
und Validierungsdatensatz mit 75% der Beobachtungen und einen Testdatensatz mit
den restlichen 25% der Beobachtungen aufgeteilt.

```{r creating baseline dataset}
# Es sollen die Messwerte zur Stunde 1 verwendet werden, aber für den Outcome
# ist der Gesamtzeitraum entscheidend
dataset1 <- data_sample_imputed %>%
  filter(Hour == 1) %>%
  select(-SepsisLabel)
```

```{r creating onset dataset}
# Es sollen die Beobachtungen zum Zeitpunkt des ersten positiven Labels verwendet
# werden, für Nicht-Sepsispatienten ein zufälliger Zeitpunkt
data_pos <- data_sample_imputed %>%
  filter(SepsisLabel == "positiv") %>%
  group_by(Patient_ID) %>%
  mutate(ersteSepsisflag = min(Hour)) %>%
  ungroup() %>%
  filter(Hour == ersteSepsisflag) %>%
  select(-ersteSepsisflag)

tmp_data_neg <- data_sample_imputed %>%
  filter(Sepsis == "negativ") %>%
  group_by(Patient_ID) %>%
  summarize(max_Hour = max(Hour),
            selected_Hour = sample(c(1:max_Hour),
                                    size = 1, replace = F)
            )

data_neg <- data_sample_imputed %>%
  filter(Sepsis == "negativ") %>%
  merge(., tmp_data_neg, by = "Patient_ID") %>%
  filter(Hour == selected_Hour) %>%
  select(-max_Hour, -selected_Hour)


dataset2 <- union_all(data_pos, data_neg) %>%
  select(-SepsisLabel) %>%
  as.data.frame()

rm(data_pos, data_neg, tmp_data_neg)
```

```{r creating regression dataset}
# Anstelle der Vital- und Laborwerte sollen die patientenindividuellen Slopes
# verwendet werden. Wenn ein Patient eine Sepsis entwickelt, wird nur der Zeitraum 
# bis zum ersten positiven Label betrachtet.

patient_model <- function(df) {
  if (sum(!is.na(df$yvalue)) < 2) NA
  else lm(yvalue ~ Hour, data = df)$coeff[2]
  }

data_pos <- data_sample_imputed %>%
  filter(SepsisLabel == "positiv") %>%
  group_by(Patient_ID) %>%
  mutate(ersteSepsisflag = min(Hour),
         ICULOS_end = min(ICULOS)) %>%
  distinct(Patient_ID, ersteSepsisflag, ICULOS_end)

data_sub <- data_sample_imputed %>%
  merge(., data_pos, by = "Patient_ID", all.x = TRUE) %>%
  filter(Sepsis == "negativ" |
           (ersteSepsisflag > 0 &  Hour <= ersteSepsisflag)
         # für ersteSepsisFlag = 0 lässt sich keine Entwicklung aufzeigen
         ) %>%
  group_by(Patient_ID) %>%
  mutate(ICULOS = case_when(!is.na(ICULOS_end) ~ ICULOS_end,
                            TRUE ~ max(ICULOS))) %>%
  ungroup() %>%
  pivot_longer(cols = HR:Platelets,
               names_to = "yvar",
               values_to = "yvalue") %>%
  mutate(yvar = paste("slope_", yvar, sep = "")) # eindeutige Namen erzeugen

by_patient <- data_sub %>%
  group_by(Patient_ID, yvar, ICULOS) %>% # damit ICULOS erhalten bleibt
  nest() %>%
  mutate(slope = map(data, patient_model)) %>%
  unnest(slope) %>%
  select(-data) %>%
  pivot_wider(names_from = yvar, values_from = slope)

dataset3 <- data_sample_imputed %>%
  distinct(Patient_ID, Age, Gender, Unit1, Unit2, HospAdmTime, Sepsis) %>%
  merge(by_patient, by = "Patient_ID", all = FALSE) %>%
  select(Patient_ID, Sepsis, everything())

rm(by_patient, data_sub, data_pos)
```

```{r train and test sets}
set.seed(12345)

# caret::createDataPartition balanciert die Outcome-Varaible aus
# der train_index für Datensatz 1 kann auch für Datensatz 2 genutzt werden (gleiche
# Patienten, gleicher Outcome)
train_index1 <- createDataPartition(dataset1$Sepsis, p = 0.75, list = FALSE)

# Datensatz 3 benötigt einen anderen train_index, da hier nicht alle Patienten 
# enthalten sind
train_index3 <- createDataPartition(dataset3$Sepsis, p = 0.75, list = FALSE)

train1 <- dataset1[train_index1,]
test1  <- dataset1[-train_index1,]
train2 <- dataset2[train_index1,]
test2  <- dataset2[-train_index1,]
train3 <- dataset3[train_index3,]
test3  <- dataset3[-train_index3,]
```

In den nächsten Abschnitten werden Entscheidungsbäume und Ensembles für jeweils
einen Datensatz angepasst. Das Tuning der Parameter und der Modellvergleich 
erfolgt mittels des R-Pakets *caret*.
Es wird eine 5-fache Kreuzvalidierung und aufgrund der sehr unausgewogenen Daten
(Eventrate `r prettyNum(
  round(
  length(unique((subset(data_sample, Sepsis == "positiv"))$Patient_ID)) /
  length(unique(data_sample$Patient_ID))   *100,
  digits = 1),
  decimal.mark = ",", big.mark = ".")` %) ein Upsampling vorgenommen.

Bei der Wahl der Evaluierungsmetrik ist zu berücksichtigen, dass sowohl
Sensitivität als auch Spezifität eine hohe Relevanz für die Fragestellung haben. 
Je höher die Sensitivität, desto mehr Patienten können frühzeitig behandelt werden,
je niedriger die Spezifität, desto mehr Patienten werden möglicherweise aufgrund
der Klassifizierung unnötigen Therapien unterzogen. Eine häufige Wahl ist in
solchen Situationen die *Area under the Curve* (ROC). In Anbetracht der 
unausgewogenen Daten kommen aber auch die PRROC-Metrik (*Area under the Precision
Recall Curve*) und die F1-Metrik (harmonisches Mittel aus Precision und Recall)
infrage. Nach Tests mit einem Teil der in dieser Arbeit evaluierten Modelle ist
hier die Entscheidung für die F1-Metrik gefallen. Diese Wahl ist nach den vorigen
Überlegungen auch intuitiv nachvollziehbar, da gleichermaßen der Anteil der richtig
positiven an den Events als auch der Anteil der richtig positiven an den positiv
klassifizierten eingeht.

```{r caret models control}
set.seed(12345)

ctrl <- trainControl(method = "cv", number = 5,
                     classProbs = TRUE,
                     summaryFunction = prSummary,
                     sampling = "up")
```

```{r tune grid rf}
rf_grid <- expand.grid(
  .mtry = seq(2,35,3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)
```

```{r tune grid gbm}
gbm_grid <-  expand.grid(interaction.depth = seq(1, 9, 2),
                        n.trees = c(50, 100, 200, 500, 1000),
                        shrinkage = c(0.001, 0.01, 0.05, 0.1),
                        n.minobsinnode = seq(10, 20, 5))
```

## Der Baseline-Ansatz

Ein CART-Modell:

```{r caret cart models ds1, include = TRUE}
set.seed(12345)

cart_ds1 <- train(x = train1[,4:41],
                  y = train1$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

cart_ds1

rpart.plot(cart_ds1$finalModel, type = 5)
# rpart.rules(cart_ds1$finalModel)

cart_ds1_Imp <- varImp(cart_ds1)
plot(cart_ds1_Imp, top = 20)

pred_cart_ds1 <- predict(cart_ds1, test1)
confusionMatrix(data = pred_cart_ds1, reference = test1$Sepsis, 
                positive = "positiv")
```

Auch wenn der CART-Algorithmus mit fehlenden Werten umgehen kann, wird zum
Vergleich ein weiterer Entscheidungsbaum mit Median-Imputation angepasst. der 
Literatur zufolge sind Entscheidungsbäume robust gegen fehlende Werte bzw. 
ungenaue Imputationen; deshalb wird diese grobe Methode verwendet:

```{r caret cart models ds1 preprocessed, include = TRUE}
set.seed(12345)

cart_proc_ds1 <- train(x = train1[,4:41],
                  y = train1$Sepsis,
                  preProcess = "medianImpute",
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

cart_proc_ds1
rpart.plot(cart_proc_ds1$finalModel, type = 5)

cart_proc_ds1_Imp <- varImp(cart_proc_ds1)
plot(cart_proc_ds1_Imp, top = 20)

pred_cart_proc_ds1 <- predict(cart_proc_ds1, test1)
confusionMatrix(data = pred_cart_proc_ds1, reference = test1$Sepsis, 
                positive = "positiv")
```

Des Weiteren werden Random Forests trainiert. Da diese Methode nicht mit fehlenden
Werten funktioniert, wird zum einen die im R-Paket *randomForest* implementierte
Imputation nach Breiman angewandt:

```{r rf model ds1, include = TRUE}
set.seed(12345)

# Imputation nach Breiman:

ds1_imputed <- rfImpute(train1$Sepsis ~ ., train1) %>%
  dplyr::rename(Sepsis = `train1$Sepsis`) %>%
  relocate(Sepsis, .after = ICULOS)

rfr_ds1 <- train(x = ds1_imputed[,4:41],
                  y = train1$Sepsis,
                  method = "ranger",
                  tuneGrid = rf_grid,
                  num.trees = 500,
                  importance = "permutation", #impurity
                  metric = "F",
                  trControl = ctrl)

rfr_ds1

# Testdaten werden nicht automatisch imputiert
pred_rfr_ds1 <- predict(rfr_ds1, rfImpute(Sepsis ~., test1)[-1])
confusionMatrix(data = pred_rfr_ds1, reference = test1$Sepsis, 
                positive = "positiv")
```

Als weiterer Ansatz wird der Datensatz auf diejenigen Prädiktoren mit weniger als
30 % fehlenden Werten eingeschränkt und anschließend  nur die vollständigen
Beobachtungen einbezogen:

```{r rf non-missing ds1, include = TRUE}
set.seed(12345)

vis_miss(dataset1)
miss_var_summary(dataset1)

train1_2 <- train1[, which(colMeans(!is.na(train1)) > 0.7)] 

# Entsprechend muss mtry im TuneGrid angepasst werden:
n_var1 <- train1_2 %>% 
  select(-Patient_ID, -X, -Hour, -Sepsis) %>% 
  ncol()
  
rf_grid1 <- expand.grid(
  .mtry = seq(2, n_var1 - 1 ,3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)

rf_nm_ds1 <- train(Sepsis ~ . - Patient_ID - X - Hour - Sepsis,
                  data = train1_2,
                  method = "ranger",
                  na.action = na.omit,
                  tuneGrid = rf_grid1,
                  metric = "F",
                  trControl = ctrl)

rf_nm_ds1

# Vorhersagen nur für vollständige Beobachtungen
test1_2 <- test1[, colnames(train1_2)] %>%
  filter(complete.cases(.))

pred_rf_nm_ds1 <- predict(rf_nm_ds1, test1_2)
confusionMatrix(data = pred_rf_nm_ds1, reference = test1_2$Sepsis, 
                positive = "positiv")
```

Während Random Forests Bäume durch Bagging kombinieren und damit insbesondere
die Korrelation zwischen den einzelnen Bäumen verringern, zielen auf Boosting
zurückgreifende Ensemble-Verfahren darauf, sukzessive die Vorhersagen für falsch
klassifizierte Beobachtungen zu verbessern. Hier wird nun zum Vergleich ein 
Stochastic Gradient Boosting mit dem R-Palet *gbm* durchgeführt:

```{r gbm model ds1, include = TRUE}
set.seed(12345)

gbm_ds1 <- train(x = train1[,4:41],
                  y = train1$Sepsis,
                  method = "gbm",
                  distribution = "bernoulli", # Adaboost und Huber führen zu mehr
                                              # richtig positiven, aber auch sehr
                                              # vielen falsch positiven
                  metric = "F",
                  tuneGrid = gbm_grid,
                  trControl = ctrl,
                  verbose = FALSE)

gbm_ds1

pred_gbm_ds1 <- predict(gbm_ds1, test1)
confusionMatrix(data = pred_gbm_ds1, reference = test1$Sepsis, 
                positive = "positiv")
```
## Der Onset-Ansatz

Auch für den Onset-Datensatz werden zunächst Entscheidungsbäume mit dem
CART-Algorithmus angepasst.

Ohne Imputation:

```{r caret cart models ds2, include = TRUE}
set.seed(12345)

cart_ds2 <- train(x = train2[,4:41],
                  y = train2$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

cart_ds2
rpart.plot(cart_ds2$finalModel, type = 5)
# rpart.rules(cart_ds2$finalModel)

cart_ds2_Imp <- varImp(cart_ds2)
plot(cart_ds2_Imp, top = 20)

pred_cart_ds2 <- predict(cart_ds2, test2)
confusionMatrix(data = pred_cart_ds2, reference = test2$Sepsis, 
                positive = "positiv")
```

Mit Median-Imputation:

```{r caret cart models ds2 preprocessed, include = TRUE}
set.seed(12345)

cart_proc_ds2 <- train(x = train2[,4:41],
                  y = train2$Sepsis,
                  preProcess = "medianImpute",
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

cart_proc_ds2
rpart.plot(cart_proc_ds2$finalModel, type = 5)

cart_proc_ds2_Imp <- varImp(cart_proc_ds2)
plot(cart_proc_ds2_Imp, top = 20)

pred_cart_proc_ds2 <- predict(cart_proc_ds2, test2)
confusionMatrix(data = pred_cart_proc_ds2, reference = test2$Sepsis,
                positive = "positiv")
```

Es folgen die Random Forests - zunächst mit Imputation nach Breiman:

```{r rf model ds2, include = TRUE}
set.seed(12345)

# Imputation nach Breiman:

ds2_imputed <- rfImpute(train2$Sepsis ~ ., train2) %>%
  dplyr::rename(Sepsis = `train2$Sepsis`) %>%
  relocate(Sepsis, .after = ICULOS)

rfr_ds2 <- train(x = ds2_imputed[,4:41],
                  y = train2$Sepsis,
                  method = "ranger",
                  tuneGrid = rf_grid,
                  num.trees = 500,
                  importance = "permutation", #impurity
                  metric = "F",
                  trControl = ctrl)

rfr_ds2

# Testdaten werden nicht automatisch imputiert
pred_rfr_ds2 <- predict(rfr_ds2, rfImpute(Sepsis ~., test2)[-1])
confusionMatrix(data = pred_rfr_ds2, reference = test2$Sepsis, 
                positive = "positiv")
```

Dann mit Einschränkung auf Prädiktoren mit weniger als 30 % fehlenden Werten
und vollständige Beobachtungen:

```{r rf non-missing ds2, include = TRUE}
set.seed(12345)

vis_miss(dataset2)
miss_var_summary(dataset2)

train2_2 <- train2[, which(colMeans(!is.na(train2)) > 0.7)] 

# Entsprechend muss mtry im TuneGrid angepasst werden:
n_var2 <- train2_2 %>% 
  select(-Patient_ID, -X, -Hour, -Sepsis) %>% 
  ncol()
  
rf_grid2 <- expand.grid(
  .mtry = seq(2, n_var2 - 1, 3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)

rf_nm_ds2 <- train(Sepsis ~ . - Patient_ID - X - Hour - Sepsis,
                  data = train2_2,
                  method = "ranger",
                  na.action = na.omit,
                  tuneGrid = rf_grid2,
                  metric = "F",
                  trControl = ctrl)

rf_nm_ds2

# Vorhersagen nur für vollständige Beobachtungen
test2_2 <- test2[, colnames(train2_2)] %>%
  filter(complete.cases(.))

pred_rf_nm_ds2 <- predict(rf_nm_ds2, test2_2)
confusionMatrix(data = pred_rf_nm_ds2, reference = test2_2$Sepsis, 
                positive = "positiv")
```

Und schließlich wird ein Gradient Boosting durchgeführt:

```{r gbm model ds2, include = TRUE}
set.seed(12345)

gbm_ds2 <- train(x = train2[,4:41],
                  y = train2$Sepsis,
                  method = "gbm",
                  distribution = "bernoulli",
                  metric = "F",
                  tuneGrid = gbm_grid,
                  trControl = ctrl,
                  verbose = FALSE)

gbm_ds2

pred_gbm_ds2 <- predict(gbm_ds2, test2)
confusionMatrix(data = pred_gbm_ds2, reference = test2$Sepsis, 
                positive = "positiv")
```

## Der Regressionsansatz

Auch für den Regressionsdatensatz werden die gleichen Verfahren benutzt.

CART:

```{r caret cart models ds3, include = TRUE}
set.seed(12345)

cart_ds3 <- train(x = train3[,3:40],
                  y = train3$Sepsis,
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

cart_ds3
rpart.plot(cart_ds3$finalModel, type = 5)
# rpart.rules(cart_ds3$finalModel)

cart_ds3_Imp <- varImp(cart_ds3)
plot(cart_ds3_Imp, top = 20)

pred_cart_ds3 <- predict(cart_ds3, test3)
confusionMatrix(data = pred_cart_ds3, reference = test3$Sepsis, 
                positive = "positiv")
```

CART nach Median-Imputation:

```{r caret cart models ds3 preprocessed, include = TRUE}
set.seed(12345)
# Median der Veränderung scheint wenig sinnvoll, aber dennoch zum Vergleich
cart_proc_ds3 <- train(x = train3[,3:40],
                  y = train3$Sepsis,
                  preProcess = "medianImpute",
                  method = "rpart",
                  metric = "F",
                  trControl = ctrl)

cart_proc_ds3
rpart.plot(cart_proc_ds3$finalModel, type = 5)

cart_proc_ds3_Imp <- varImp(cart_proc_ds3)
plot(cart_proc_ds3_Imp, top = 20)

pred_cart_proc_ds3 <- predict(cart_proc_ds3, test3)
confusionMatrix(data = pred_cart_proc_ds3, reference = test3$Sepsis, 
                positive = "positiv")
```

Random Forest mit Imputation nach Breiman:

```{r rf model ds3, include = TRUE}
set.seed(12345)

# Imputation nach Breiman:

ds3_imputed <- rfImpute(train3$Sepsis ~ ., train3) %>%
  dplyr::rename(Sepsis = `train3$Sepsis`)

rfr_ds3 <- train(x = ds3_imputed[,3:40],
                  y = train3$Sepsis,
                  method = "ranger",
                  tuneGrid = rf_grid,
                  num.trees = 500,
                  importance = "permutation", #impurity
                  metric = "F",
                  trControl = ctrl)

rfr_ds3

# Testdaten werden nicht automatisch imputiert
pred_rfr_ds3 <- predict(rfr_ds3, rfImpute(Sepsis ~., test3)[-1])
confusionMatrix(data = pred_rfr_ds3, reference = test3$Sepsis,
                positive = "positiv")
```

Random Forest nach Einschränkung der Prädiktoren und auf vollständige
Beobachtungen:

```{r rf non-missing ds3, include = TRUE}
set.seed(12345)

vis_miss(dataset3)
miss_var_summary(dataset3)

train3_2 <- train3[, which(colMeans(!is.na(train3)) > 0.7)]

# Entsprechend muss mtry im TuneGrid angepasst werden:
n_var3 <- train3_2 %>% 
  select(-Patient_ID, -Sepsis) %>% 
  ncol()
  
rf_grid3 <- expand.grid(
  .mtry = seq(2, n_var3 - 1, 3),
  .splitrule = "gini",
  .min.node.size = seq(5, 20, 5)
)

rf_nm_ds3 <- train(Sepsis ~ . - Patient_ID - Sepsis,
                  data = train3_2,
                  method = "ranger",
                  na.action = na.omit,
                  tuneGrid = rf_grid3,
                  metric = "F",
                  trControl = ctrl)

rf_nm_ds3

# Vorhersagen nur für vollständige Beobachtungen
test3_2 <- test3[, colnames(train3_2)] %>%
  filter(complete.cases(.))

pred_rf_nm_ds3 <- predict(rf_nm_ds3, test3_2)
confusionMatrix(data = pred_rf_nm_ds3, reference = test3_2$Sepsis, 
                positive = "positiv")
```

Gradient Boosting:

```{r gbm model ds3, include = TRUE}
set.seed(12345)

gbm_ds3 <- train(x = train3[,3:40],
                  y = train3$Sepsis,
                  method = "gbm",
                  distribution = "bernoulli", # Huber nicht besser, 
                                              # Adaboost schlechter
                  metric = "F",
                  tuneGrid = gbm_grid,
                  trControl = ctrl,
                  verbose = FALSE)

gbm_ds3

pred_gbm_ds3 <- predict(gbm_ds3, test3)
confusionMatrix(data = pred_gbm_ds3, reference = test3$Sepsis, 
                positive = "positiv")
```

## Vergleich der Modelle

```{r resamples, include = TRUE}
results <- resamples(list(ds1_cart_raw = cart_ds1, ds1_cart_median = cart_proc_ds1,
                          ds2_cart_raw = cart_ds2, ds2_cart_median = cart_proc_ds2,
                          ds3_cart_raw = cart_ds3, ds3_cart_median = cart_proc_ds3,
                          ds1_rf_rfImpute = rfr_ds1, ds1_rf_nonmissing = rf_nm_ds1,
                          ds2_rf_rfImpute = rfr_ds2, ds2_rf_nonmissing = rf_nm_ds2,
                          ds3_rf_rfImpute = rfr_ds3, ds3_rf_nonmissing = rf_nm_ds3,
                          ds1_gbm = gbm_ds1, ds2_gbm = gbm_ds2, ds3_gbm = gbm_ds3))

summary(results)

dotplot(results)
```

# Anhang

Es wurden folgende Pakete und Versionen von R genutzt:

```{r session info, include = TRUE}
sessioninfo::platform_info()$version
subset(data.frame(sessioninfo::package_info()), attached == TRUE, 
       c(loadedversion))
```

```{r vars description, include = TRUE}
# knitr::kable(var_info, booktabs = T,
#              caption = "Datensatzbeschreibung (Variablen)") %>%
#   kable_styling(latex_options = c("striped", "scale_down"),
#                 position = "center")
```

# Referenzen
